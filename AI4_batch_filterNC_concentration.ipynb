{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter nc by concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import netCDF4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Paths to folders\n",
    "input_folder = r'E:\\Sea Ice Classification\\AI4ArcticASIP Sea ice Dataset version2'\n",
    "output_csv_dir = os.path.join(input_folder, '70csv_output')\n",
    "selected_nc_dir = os.path.join(input_folder, 'selected_nc_files')\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(output_csv_dir, exist_ok=True)\n",
    "os.makedirs(selected_nc_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Iterate through .nc files\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.nc'):\n",
    "        nc_file = os.path.join(input_folder, filename)\n",
    "        file_base = os.path.splitext(filename)[0]\n",
    "\n",
    "        try:\n",
    "            # Open the .nc file\n",
    "            ncf = netCDF4.Dataset(nc_file)\n",
    "\n",
    "            # Check for polygon data\n",
    "            if 'polygon_icechart' in ncf.variables and 'polygon_codes' in ncf.variables:\n",
    "                polygon_codes = ncf.variables['polygon_codes'][:]\n",
    "\n",
    "                # Save polygon_codes to CSV\n",
    "                out_csv_filename = os.path.join(output_csv_dir, f'{file_base}_PolygonCodes.csv')\n",
    "                with open(out_csv_filename, mode='w', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow(['Index', 'Code'])\n",
    "                    writer.writerows(enumerate(polygon_codes))\n",
    "\n",
    "                print(f\"Saved CSV for {file_base}\")\n",
    "\n",
    "                # Split and save CSV columns\n",
    "                df = pd.read_csv(out_csv_filename)\n",
    "                df_split = df['Code'].str.split(';', expand=True)\n",
    "                df_split.columns = ['id', 'CT', 'CA', 'SA', 'FA', 'CB', 'SB', 'FB', 'CC', 'SC', 'FC', 'CN', 'CD', 'CF', 'POLY_TYPE']\n",
    "                final_df = pd.concat([df['Index'], df_split], axis=1)\n",
    "                final_csv_filename = os.path.join(output_csv_dir, f'{file_base}_separated_columns.csv')\n",
    "                final_df.to_csv(final_csv_filename, index=False)\n",
    "                print(f\"Saved separated columns CSV for {file_base}\")\n",
    "\n",
    "                # Check columns for data > 70\n",
    "                if final_df[['CA', 'CB', 'CC']].apply(pd.to_numeric, errors='coerce').max().max() > 70:\n",
    "                    shutil.copy(nc_file, os.path.join(selected_nc_dir, filename))\n",
    "                    print(f\"File {filename} contains values > 70 in CA/CB/CC and was copied.\")\n",
    "\n",
    "            ncf.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
